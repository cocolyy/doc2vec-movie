{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from scipy.spatial import distance\n",
    "import re\n",
    "from random import shuffle\n",
    "import string\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import pickle\n",
    "import pprint\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('dataset/movies.csv', index_col=0) \n",
    "df_final.dropna(inplace=True)\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "df_final['Description'] = df_final['Description'].apply(lambda x: str(x).strip())\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"turkish\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    new_string = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return new_string\n",
    "\n",
    "# Description only\n",
    "df_final['cleaned'] = df_final['Description']\n",
    "# Stars + Directors + Description\n",
    "df_final = df_final.assign(combine=[(f'''{str(df_final[\"Title\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")} ,\n",
    "{str(df_final[\"Genres\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")} ,\n",
    "{str(df_final[\"Stars\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")} ,\n",
    "{str(df_final[\"Stars\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")} ,\n",
    "{str(df_final[\"Director\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")},\n",
    "{str(df_final[\"Genres\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")},\n",
    "{str(df_final[\"Genres\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")}''').lower() for i in range(len(df_final[\"Title\"]))])\n",
    "# Title + Description\n",
    "df_final = df_final.assign(temp_f=[(f'''{str(df_final[\"Stars\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")}, {str(df_final[\"Director\"][i]).strip(\"[]\").replace(\"'\", \"\").replace(\",\",\".\")}, {df_final['Description']}''').lower() for i in range(len(df_final[\"Title\"]))])\n",
    "\n",
    "df_final['cleaned'] = df_final.cleaned.apply(func = make_lower_case)\n",
    "df_final['cleaned'] = df_final.cleaned.apply(func = remove_stop_words)\n",
    "df_final['cleaned'] = df_final.cleaned.apply(func = remove_punctuation)\n",
    "df_final['cleaned'] = df_final.cleaned.apply(func = remove_html)\n",
    "\n",
    "df_final['combine'] = df_final['combine'].apply(func = make_lower_case)\n",
    "df_final['combine'] = df_final['combine'].apply(func = remove_stop_words)\n",
    "df_final['combine'] = df_final['combine'].apply(func = remove_punctuation)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(row['combine']), tags=[row['Title']]) for index, row in df_final.iterrows()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yüzüklerin Efendisi: İki Kule'] :  ['yüzüklerin', 'efendisi', 'i̇ki', 'kule', 'fantastik', 'macera', 'elijah', 'wood', 'sean', 'astin', 'viggo', 'mortensen', 'elijah', 'wood', 'sean', 'astin', 'viggo', 'mortensen', 'peter', 'jackson', 'fantastik', 'macera', 'fantastik', 'macera']\n"
     ]
    }
   ],
   "source": [
    "print(tagged_data[471].tags, ': ', (tagged_data[471].words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 18:30:25,498 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t12>', 'datetime': '2023-02-22T18:30:25.498286', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-02-22 18:30:25,499 : INFO : collecting all words and their counts\n",
      "2023-02-22 18:30:25,499 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-02-22 18:30:25,537 : INFO : PROGRESS: at example #10000, processed 225567 words (5892077 words/s), 26085 word types, 9472 tags\n",
      "2023-02-22 18:30:25,621 : INFO : collected 42687 word types and 17513 unique tags from a corpus of 18492 examples and 414804 words\n",
      "2023-02-22 18:30:25,622 : INFO : Creating a fresh vocabulary\n",
      "2023-02-22 18:30:25,650 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 10246 unique words (24.00% of original 42687, drops 32441)', 'datetime': '2023-02-22T18:30:25.650462', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-22 18:30:25,651 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 353881 word corpus (85.31% of original 414804, drops 60923)', 'datetime': '2023-02-22T18:30:25.651464', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-22 18:30:25,685 : INFO : deleting the raw counts dictionary of 42687 items\n",
      "2023-02-22 18:30:25,686 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2023-02-22 18:30:25,686 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 278835.0016274331 word corpus (78.8%% of prior 353881)', 'datetime': '2023-02-22T18:30:25.686997', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-22 18:30:25,745 : INFO : estimated required memory for 10246 words and 200 dimensions: 39029600 bytes\n",
      "2023-02-22 18:30:25,745 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t12>\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(\n",
    "    dm=0, dbow_words=1,\n",
    "    vector_size=200, window=8, epochs=20, workers=12,\n",
    ")\n",
    "\n",
    "model_dbow.build_vocab(tagged_data)\n",
    "print(model_dbow)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 18:30:25,803 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 12 workers on 10246 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-22T18:30:25.803501', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-02-22 18:30:26,988 : INFO : EPOCH 0 - PROGRESS: at 59.90% examples, 156785 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:27,128 : INFO : EPOCH 0: training on 414804 raw words (297418 effective words) took 1.3s, 226331 effective words/s\n",
      "2023-02-22 18:30:28,337 : INFO : EPOCH 1 - PROGRESS: at 59.90% examples, 153212 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:28,485 : INFO : EPOCH 1: training on 414804 raw words (297129 effective words) took 1.3s, 220399 effective words/s\n",
      "2023-02-22 18:30:29,735 : INFO : EPOCH 2 - PROGRESS: at 59.90% examples, 148354 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:29,904 : INFO : EPOCH 2: training on 414804 raw words (297280 effective words) took 1.4s, 210955 effective words/s\n",
      "2023-02-22 18:30:31,145 : INFO : EPOCH 3 - PROGRESS: at 59.90% examples, 150181 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:31,283 : INFO : EPOCH 3: training on 414804 raw words (297169 effective words) took 1.4s, 218107 effective words/s\n",
      "2023-02-22 18:30:32,527 : INFO : EPOCH 4 - PROGRESS: at 59.90% examples, 149138 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:32,670 : INFO : EPOCH 4: training on 414804 raw words (297310 effective words) took 1.4s, 216022 effective words/s\n",
      "2023-02-22 18:30:33,915 : INFO : EPOCH 5 - PROGRESS: at 59.90% examples, 148880 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:34,068 : INFO : EPOCH 5: training on 414804 raw words (297350 effective words) took 1.4s, 214218 effective words/s\n",
      "2023-02-22 18:30:35,304 : INFO : EPOCH 6 - PROGRESS: at 59.90% examples, 149697 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:35,448 : INFO : EPOCH 6: training on 414804 raw words (297038 effective words) took 1.4s, 216655 effective words/s\n",
      "2023-02-22 18:30:36,689 : INFO : EPOCH 7 - PROGRESS: at 59.90% examples, 149458 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:36,833 : INFO : EPOCH 7: training on 414804 raw words (297307 effective words) took 1.4s, 216029 effective words/s\n",
      "2023-02-22 18:30:38,053 : INFO : EPOCH 8 - PROGRESS: at 59.90% examples, 152022 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:38,192 : INFO : EPOCH 8: training on 414804 raw words (297362 effective words) took 1.4s, 220161 effective words/s\n",
      "2023-02-22 18:30:39,421 : INFO : EPOCH 9 - PROGRESS: at 59.93% examples, 151418 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:39,561 : INFO : EPOCH 9: training on 414804 raw words (297435 effective words) took 1.4s, 219537 effective words/s\n",
      "2023-02-22 18:30:40,776 : INFO : EPOCH 10 - PROGRESS: at 59.90% examples, 152500 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:40,921 : INFO : EPOCH 10: training on 414804 raw words (297333 effective words) took 1.4s, 220181 effective words/s\n",
      "2023-02-22 18:30:42,159 : INFO : EPOCH 11 - PROGRESS: at 59.90% examples, 149873 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:42,309 : INFO : EPOCH 11: training on 414804 raw words (297470 effective words) took 1.4s, 215606 effective words/s\n",
      "2023-02-22 18:30:43,515 : INFO : EPOCH 12 - PROGRESS: at 59.95% examples, 153798 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:43,670 : INFO : EPOCH 12: training on 414804 raw words (297208 effective words) took 1.4s, 220017 effective words/s\n",
      "2023-02-22 18:30:44,879 : INFO : EPOCH 13 - PROGRESS: at 59.90% examples, 153385 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:45,027 : INFO : EPOCH 13: training on 414804 raw words (297383 effective words) took 1.3s, 220533 effective words/s\n",
      "2023-02-22 18:30:46,238 : INFO : EPOCH 14 - PROGRESS: at 59.95% examples, 153236 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:46,387 : INFO : EPOCH 14: training on 414804 raw words (297460 effective words) took 1.4s, 220286 effective words/s\n",
      "2023-02-22 18:30:47,607 : INFO : EPOCH 15 - PROGRESS: at 59.90% examples, 152167 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:47,745 : INFO : EPOCH 15: training on 414804 raw words (297425 effective words) took 1.3s, 220672 effective words/s\n",
      "2023-02-22 18:30:48,969 : INFO : EPOCH 16 - PROGRESS: at 59.90% examples, 152112 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:49,112 : INFO : EPOCH 16: training on 414804 raw words (297536 effective words) took 1.4s, 219831 effective words/s\n",
      "2023-02-22 18:30:50,339 : INFO : EPOCH 17 - PROGRESS: at 59.93% examples, 150942 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:50,483 : INFO : EPOCH 17: training on 414804 raw words (297239 effective words) took 1.4s, 218231 effective words/s\n",
      "2023-02-22 18:30:51,700 : INFO : EPOCH 18 - PROGRESS: at 59.90% examples, 152424 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:51,849 : INFO : EPOCH 18: training on 414804 raw words (297432 effective words) took 1.4s, 219160 effective words/s\n",
      "2023-02-22 18:30:53,066 : INFO : EPOCH 19 - PROGRESS: at 59.90% examples, 152407 words/s, in_qsize 17, out_qsize 0\n",
      "2023-02-22 18:30:53,211 : INFO : EPOCH 19: training on 414804 raw words (297490 effective words) took 1.4s, 219860 effective words/s\n",
      "2023-02-22 18:30:53,212 : INFO : Doc2Vec lifecycle event {'msg': 'training on 8296080 raw words (5946774 effective words) took 27.4s, 216977 effective words/s', 'datetime': '2023-02-22T18:30:53.212637', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-02-22 18:30:53,212 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-22T18:30:53.212637', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2023-02-22 18:30:53,213 : INFO : not storing attribute cum_table\n",
      "2023-02-22 18:30:53,237 : INFO : saved doc2vec.model\n"
     ]
    }
   ],
   "source": [
    "model_dbow.train(tagged_data, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
    "model_dbow.save(\"doc2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Iron Man', 0.9398001432418823),\n",
      "    ('Iron Man 3', 0.8286119699478149),\n",
      "    ('Iron Man 2', 0.8158987760543823),\n",
      "    ('Yenilmezler', 0.7131946086883545),\n",
      "    ('Red Tails', 0.7069835066795349),\n",
      "    ('Sky Captain ve Yarının Dünyası', 0.6855823993682861),\n",
      "    ('Avengers: Endgame', 0.6840946674346924),\n",
      "    ('Yenilmezler: Ultron Çağı', 0.6807721853256226),\n",
      "    ('Avengers: Sonsuzluk Savaşı', 0.6733619570732117),\n",
      "    ('Jurassic World: Hakimiyet', 0.6591430306434631),\n",
      "    ('Air America', 0.6523217558860779),\n",
      "    ('Sherlock Holmes', 0.6520013213157654),\n",
      "    ('Örümcek-Adam: Eve Dönüş', 0.6508820652961731),\n",
      "    ('Yüksek Gerilim', 0.6480500102043152),\n",
      "    ('Gothika', 0.6461778879165649),\n",
      "    ('Dövüş', 0.645106315612793),\n",
      "    ('Fur: An Imaginary Portrait of Diane Arbus', 0.6416605710983276),\n",
      "    ('A Scanner Darkly', 0.639180600643158),\n",
      "    ('Tuff Turf', 0.638505220413208),\n",
      "    ('Kanıt', 0.6371035575866699)]\n",
      "iron man aksiyon bilimkurgu robert downey jr terrence howard gwyneth paltrow robert downey jr terrence howard gwyneth paltrow jon favreau aksiyon bilimkurgu aksiyon bilimkurgu\n"
     ]
    }
   ],
   "source": [
    "def search_by_tag(tag):\n",
    "    for doc in tagged_data:\n",
    "        if doc.tags[0] == tag:\n",
    "            return \" \".join(doc.words)\n",
    "\n",
    "def return_most_similar(mov_title) -> list:\n",
    "  tokens = remove_html(remove_punctuation(remove_stop_words(make_lower_case(search_by_tag(mov_title))))).split()\n",
    "  vector = model_dbow.infer_vector(tokens)\n",
    "  most_similar = model_dbow.dv.most_similar([vector], topn=20) \n",
    "  return most_similar\n",
    "\n",
    "def return_token(mov_title) -> list:\n",
    "  tokens = remove_html(remove_punctuation(remove_stop_words(make_lower_case(search_by_tag(mov_title))))).split()\n",
    "  return tokens\n",
    "\n",
    "def return_most_similar_token(vec) -> list:\n",
    "  # len(df_final['Title']\n",
    "  most_similar = model_dbow.dv.most_similar([vec],topn=20)\n",
    "  return most_similar\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "seed_text = 'Iron Man'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)\n",
    "print(search_by_tag(seed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Dune:Çöl Gezegeni', 0.9543393850326538),\n",
      "    ('Dune: Part Two', 0.9015074372291565),\n",
      "    ('Hayat', 0.718077540397644),\n",
      "    ('Ex Machina', 0.6980426907539368),\n",
      "    ('Metal Gear Solid', 0.6805034279823303),\n",
      "    ('Trendeki Kız', 0.6732518076896667),\n",
      "    ('Star Wars: Son Jedi', 0.6704469323158264),\n",
      "    ('Kardan Adam', 0.6681733727455139),\n",
      "    (\"Star Wars: Skywalker'ın Yükselişi\", 0.6627540588378906),\n",
      "    (\"Won't Back Down\", 0.6611697673797607),\n",
      "    ('Mojave', 0.6510500311851501),\n",
      "    ('Her Şey Olacağına Varır', 0.649515688419342),\n",
      "    ('Zihin Gezgini', 0.647402822971344),\n",
      "    ('Zehirli Element', 0.6454704403877258),\n",
      "    ('Doktor Uyku', 0.638755202293396),\n",
      "    ('Francis And The Godfather', 0.6355670094490051),\n",
      "    ('London', 0.6329144239425659),\n",
      "    ('Beni Adınla Çağır', 0.6269508004188538),\n",
      "    ('Teen Spirit', 0.6261535882949829),\n",
      "    ('Ocak Ayının İki Yüzü', 0.6254170536994934)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Dune:Çöl Gezegeni'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Yüzüklerin Efendisi: İki Kule', 0.9456788301467896),\n",
      "    ('Yüzüklerin Efendisi: Yüzük Kardeşliği', 0.8622255921363831),\n",
      "    ('On Üç Yaşam', 0.6091465950012207),\n",
      "    ('Kurbağa Prens', 0.6070922613143921),\n",
      "    ('Woodlawn', 0.5981312990188599),\n",
      "    ('The Goonies', 0.5964442491531372),\n",
      "    ('Şiddetin Tarihçesi', 0.5905812382698059),\n",
      "    ('Rumpelstiltskin', 0.5901864171028137),\n",
      "    ('Tuhaf Bir Sihir', 0.5881508588790894),\n",
      "    ('Try Seventeen', 0.5879155993461609),\n",
      "    ('Yeşil Rehber', 0.5850781798362732),\n",
      "    ('Yeşil Sokak Holiganları', 0.5835225582122803),\n",
      "    ('Hero Mode', 0.5830981135368347),\n",
      "    ('Time Bandits', 0.5801665186882019),\n",
      "    ('Kanun Benim', 0.579239010810852),\n",
      "    ('Düşüş', 0.5744485259056091),\n",
      "    ('Offence, The', 0.5720624327659607),\n",
      "    ('Şark Vaatleri', 0.568449854850769),\n",
      "    ('Gerçeğin İki Yüzü', 0.5681962966918945),\n",
      "    ('Pitch Perfect', 0.5618053674697876)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Yüzüklerin Efendisi: İki Kule'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Rashômon', 0.9667608141899109),\n",
      "    ('Yüksek ve Alçak', 0.886763334274292),\n",
      "    ('Yojimbo', 0.8776783347129822),\n",
      "    ('Sanjuro', 0.8773446679115295),\n",
      "    ('Kanlı Taht', 0.8740440607070923),\n",
      "    ('Ran', 0.8683363795280457),\n",
      "    ('Akahige', 0.8680164217948914),\n",
      "    ('Dava Vekili', 0.8570104837417603),\n",
      "    ('Yedi Samuray', 0.8538091778755188),\n",
      "    ('Akasen Chitai', 0.8534561991691589),\n",
      "    ('Floating Weeds', 0.8412061333656311),\n",
      "    ('Ichimei', 0.8389753699302673),\n",
      "    ('Tokyo Sonatı', 0.8376791477203369),\n",
      "    ('Gizli Kale', 0.8375594615936279),\n",
      "    ('37 Seconds', 0.8366216421127319),\n",
      "    ('Ugetsu', 0.8340597748756409),\n",
      "    ('Geç Sonbahar', 0.8333784341812134),\n",
      "    ('Cold Fish', 0.8316842913627625),\n",
      "    ('Cut', 0.8286798596382141),\n",
      "    ('Chikamatsu monogatari', 0.8266655206680298)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Rashômon'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Titanik', 0.9382817149162292),\n",
      "    ('Şöhrete İlk Adım', 0.7013309597969055),\n",
      "    ('Fake !', 0.6686000227928162),\n",
      "    ('The Wager', 0.660822868347168),\n",
      "    ('The Black Hand', 0.6597444415092468),\n",
      "    ('Boşanma', 0.6544262170791626),\n",
      "    ('Bu Çocuğun Hayatı', 0.6543473601341248),\n",
      "    ('Enigma', 0.6496071219444275),\n",
      "    ('Tutku Oyunları', 0.6491042971611023),\n",
      "    ('Tatil', 0.6438833475112915),\n",
      "    ('Hayallerin Peşinde', 0.6434882283210754),\n",
      "    ('Orlando', 0.640713632106781),\n",
      "    ('Roosevelt', 0.6402652263641357),\n",
      "    ('Iris', 0.6394973993301392),\n",
      "    (\"Don's Plum\", 0.6316646933555603),\n",
      "    ('Bu Dünya ve Ötesi', 0.6299759745597839),\n",
      "    ('Kutsal Duman', 0.6259361505508423),\n",
      "    ('Okuyucu', 0.6205527782440186),\n",
      "    ('Amsterdam Ekspres', 0.6186784505844116),\n",
      "    ('127 Saat', 0.6186205744743347)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Titanik'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dict has title:embedding -> embeddings are created using that specific movie's plot\n",
    "movie_embeddings = {title: model_dbow.infer_vector(return_token(title)) for title in df_final['Title']}\n",
    "\n",
    "with open(\"movie_embed_desc.pickle\", \"wb\") as f:\n",
    "    pickle.dump(movie_embeddings, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(row['cleaned']), tags=[row['Title']]) for index, row in df_final.iterrows()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yüzüklerin Efendisi: İki Kule'] :  ['yüzüklerin', 'efendisi', 'i̇ki', 'kulede', 'yüzük', 'kardeşliği', 'üyelerinin', 'birinin', 'kardeşlik', 'bozulduktan', 'sonra', 'başlarına', 'gelenler', 'anlatılıyor', 'kahramanlarımız', 'gruplar', 'halinde', 'orta', 'dünya', '’', 'nın', 'tehlikeli', 'yerlerinde', 'maceralar', 'yaşayacaklar', 'yeni', 'kavimler', 'çoktan', 'unutulmuş', 'medeniyetlerle', 'tanışacaklarfrodo', 'sam', 'yanlarında', 'zorunlu', 'işbirliği', 'yapacakları', 'eski', 'bir', 'dost', 'olduğu', 'halde', 'tek', 'yüzük', '’', 'ü', 'düşmanın', 'tam', 'kalbine', 'götürmeye', 'çalışırken', 'diğer', 'hobbitler', 'urukhai', '’', 'nin', 'elinden', 'kurtulabilecek', 'mi', 'karanlık', 'tarafa', 'geçmiş', 'olan', 'saruman', '’', 'ın', 'yaptıkları', 'yanına', 'kalacak', 'gandalf', 'olmadan', 'kahramanlarımızın', 'başarılı', 'olma', 'şansı', 'ne', 'büyük', 'karanlığın', 'gelişi', 'yüzük', 'savaşı', '’', 'na', 'dek', 'olanların', 'anlatılacağı', 'i̇ki', 'kule', 'kuşkusuz', 'üçlemenin', 'heyecanlı', 'bölümlerinden', 'birini', 'oluşturuyorjrr', 'tolkien', '’', 'in', '3', 'kitaplık', 'ölümsüz', 'eserinden', 'uyarlanarak', 'bir', 'yılı', 'aşkın', 'süren', 'çekimler', 'sonucu', 'bir', 'arada', 'çekilen', '3', 'filmden', 'ikincisi', 'olan', 'i̇ki', 'kule', '2002', 'aralık', 'ayında', 'vizyona', 'girmek', 'üzere', 'montajlanıyor', 'son', 'rötuşları', 'yapılıyor']\n"
     ]
    }
   ],
   "source": [
    "print(tagged_data[471].tags, ': ', (tagged_data[471].words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 18:31:18,282 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t12>', 'datetime': '2023-02-22T18:31:18.282417', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-02-22 18:31:18,285 : INFO : collecting all words and their counts\n",
      "2023-02-22 18:31:18,285 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-02-22 18:31:18,427 : INFO : PROGRESS: at example #10000, processed 823740 words (5833100 words/s), 95690 word types, 9472 tags\n",
      "2023-02-22 18:31:18,570 : INFO : collected 126855 word types and 17513 unique tags from a corpus of 18492 examples and 1339673 words\n",
      "2023-02-22 18:31:18,570 : INFO : Creating a fresh vocabulary\n",
      "2023-02-22 18:31:18,644 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 26434 unique words (20.84% of original 126855, drops 100421)', 'datetime': '2023-02-22T18:31:18.644621', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-22 18:31:18,644 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1187186 word corpus (88.62% of original 1339673, drops 152487)', 'datetime': '2023-02-22T18:31:18.644621', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-22 18:31:18,732 : INFO : deleting the raw counts dictionary of 126855 items\n",
      "2023-02-22 18:31:18,734 : INFO : sample=0.001 downsamples 15 most-common words\n",
      "2023-02-22 18:31:18,735 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1096762.473020063 word corpus (92.4%% of prior 1187186)', 'datetime': '2023-02-22T18:31:18.735706', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-22 18:31:18,883 : INFO : estimated required memory for 26434 words and 200 dimensions: 73024400 bytes\n",
      "2023-02-22 18:31:18,884 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t12>\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(\n",
    "    dm=0, dbow_words=1,\n",
    "    vector_size=200, window=8, epochs=20, workers=12,\n",
    ")\n",
    "\n",
    "model_dbow.build_vocab(tagged_data)\n",
    "print(model_dbow)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 18:31:18,929 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 12 workers on 26434 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-22T18:31:18.929147', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-02-22 18:31:20,064 : INFO : EPOCH 0 - PROGRESS: at 46.21% examples, 534037 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:21,044 : INFO : EPOCH 0: training on 1339673 raw words (1115014 effective words) took 2.1s, 528532 effective words/s\n",
      "2023-02-22 18:31:22,068 : INFO : EPOCH 1 - PROGRESS: at 36.82% examples, 495621 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:23,084 : INFO : EPOCH 1 - PROGRESS: at 87.14% examples, 492978 words/s, in_qsize 14, out_qsize 0\n",
      "2023-02-22 18:31:23,214 : INFO : EPOCH 1: training on 1339673 raw words (1115483 effective words) took 2.2s, 515330 effective words/s\n",
      "2023-02-22 18:31:24,332 : INFO : EPOCH 2 - PROGRESS: at 46.25% examples, 542998 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:25,210 : INFO : EPOCH 2: training on 1339673 raw words (1115326 effective words) took 2.0s, 560206 effective words/s\n",
      "2023-02-22 18:31:26,315 : INFO : EPOCH 3 - PROGRESS: at 46.25% examples, 548811 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:27,215 : INFO : EPOCH 3: training on 1339673 raw words (1115185 effective words) took 2.0s, 557816 effective words/s\n",
      "2023-02-22 18:31:28,334 : INFO : EPOCH 4 - PROGRESS: at 46.25% examples, 541890 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:29,204 : INFO : EPOCH 4: training on 1339673 raw words (1115443 effective words) took 2.0s, 561997 effective words/s\n",
      "2023-02-22 18:31:30,277 : INFO : EPOCH 5 - PROGRESS: at 46.25% examples, 565605 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:31,131 : INFO : EPOCH 5: training on 1339673 raw words (1115454 effective words) took 1.9s, 580557 effective words/s\n",
      "2023-02-22 18:31:32,222 : INFO : EPOCH 6 - PROGRESS: at 46.21% examples, 555731 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:33,081 : INFO : EPOCH 6: training on 1339673 raw words (1115437 effective words) took 1.9s, 573224 effective words/s\n",
      "2023-02-22 18:31:34,195 : INFO : EPOCH 7 - PROGRESS: at 46.25% examples, 544857 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:35,036 : INFO : EPOCH 7: training on 1339673 raw words (1115115 effective words) took 2.0s, 571763 effective words/s\n",
      "2023-02-22 18:31:36,100 : INFO : EPOCH 8 - PROGRESS: at 46.25% examples, 570792 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:36,954 : INFO : EPOCH 8: training on 1339673 raw words (1115319 effective words) took 1.9s, 583343 effective words/s\n",
      "2023-02-22 18:31:38,060 : INFO : EPOCH 9 - PROGRESS: at 46.19% examples, 547755 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:38,955 : INFO : EPOCH 9: training on 1339673 raw words (1115068 effective words) took 2.0s, 558391 effective words/s\n",
      "2023-02-22 18:31:40,038 : INFO : EPOCH 10 - PROGRESS: at 46.25% examples, 560749 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:40,895 : INFO : EPOCH 10: training on 1339673 raw words (1115403 effective words) took 1.9s, 576892 effective words/s\n",
      "2023-02-22 18:31:41,956 : INFO : EPOCH 11 - PROGRESS: at 46.25% examples, 571383 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:42,832 : INFO : EPOCH 11: training on 1339673 raw words (1115318 effective words) took 1.9s, 577108 effective words/s\n",
      "2023-02-22 18:31:43,932 : INFO : EPOCH 12 - PROGRESS: at 46.25% examples, 551421 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:44,821 : INFO : EPOCH 12: training on 1339673 raw words (1115293 effective words) took 2.0s, 562174 effective words/s\n",
      "2023-02-22 18:31:45,911 : INFO : EPOCH 13 - PROGRESS: at 46.25% examples, 557371 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:46,787 : INFO : EPOCH 13: training on 1339673 raw words (1115223 effective words) took 2.0s, 569514 effective words/s\n",
      "2023-02-22 18:31:47,850 : INFO : EPOCH 14 - PROGRESS: at 46.25% examples, 571367 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:48,722 : INFO : EPOCH 14: training on 1339673 raw words (1115187 effective words) took 1.9s, 578195 effective words/s\n",
      "2023-02-22 18:31:49,857 : INFO : EPOCH 15 - PROGRESS: at 46.25% examples, 534549 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:50,716 : INFO : EPOCH 15: training on 1339673 raw words (1115278 effective words) took 2.0s, 560700 effective words/s\n",
      "2023-02-22 18:31:51,790 : INFO : EPOCH 16 - PROGRESS: at 46.25% examples, 564689 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:52,629 : INFO : EPOCH 16: training on 1339673 raw words (1115276 effective words) took 1.9s, 584717 effective words/s\n",
      "2023-02-22 18:31:53,691 : INFO : EPOCH 17 - PROGRESS: at 46.25% examples, 570902 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:54,571 : INFO : EPOCH 17: training on 1339673 raw words (1115157 effective words) took 1.9s, 575671 effective words/s\n",
      "2023-02-22 18:31:55,674 : INFO : EPOCH 18 - PROGRESS: at 46.25% examples, 549353 words/s, in_qsize 24, out_qsize 0\n",
      "2023-02-22 18:31:56,527 : INFO : EPOCH 18: training on 1339673 raw words (1115213 effective words) took 2.0s, 571581 effective words/s\n",
      "2023-02-22 18:31:57,598 : INFO : EPOCH 19 - PROGRESS: at 46.25% examples, 566421 words/s, in_qsize 23, out_qsize 0\n",
      "2023-02-22 18:31:58,468 : INFO : EPOCH 19: training on 1339673 raw words (1115354 effective words) took 1.9s, 575773 effective words/s\n",
      "2023-02-22 18:31:58,469 : INFO : Doc2Vec lifecycle event {'msg': 'training on 26793460 raw words (22305546 effective words) took 39.5s, 564128 effective words/s', 'datetime': '2023-02-22T18:31:58.469959', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-02-22 18:31:58,469 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-22T18:31:58.469959', 'gensim': '4.3.0', 'python': '3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2023-02-22 18:31:58,471 : INFO : not storing attribute cum_table\n",
      "2023-02-22 18:31:58,514 : INFO : saved doc2vec.model\n"
     ]
    }
   ],
   "source": [
    "model_dbow.train(tagged_data, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
    "model_dbow.save(\"doc2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Iron Man', 0.9322595000267029),\n",
      "    ('Superlópez', 0.4410777688026428),\n",
      "    (\"Oflu Hoca Trakya'da\", 0.4244818687438965),\n",
      "    ('Rounding Third', 0.4170389473438263),\n",
      "    ('Kickboxer: Vengeance', 0.40591973066329956),\n",
      "    ('Xin Shen Bang: Ne Zha Chongsheng', 0.40542253851890564),\n",
      "    ('Tron', 0.4036935865879059),\n",
      "    ('Ölümsüzlerin Savaşı', 0.40248310565948486),\n",
      "    ('Kontroll', 0.40003448724746704),\n",
      "    ('Ani Ölüm', 0.39879336953163147),\n",
      "    ('Operation Seawolf', 0.3970690667629242),\n",
      "    ('Avengers Confidential: Black Widow & Punisher', 0.39299845695495605),\n",
      "    ('Hard Kill', 0.3912982940673828),\n",
      "    ('Hava Kuvvetleri Bir', 0.39031556248664856),\n",
      "    ('Sessiz Düşman', 0.388791561126709),\n",
      "    (\"Entebbe'de 7 Gün\", 0.3879695534706116),\n",
      "    ('Vexille', 0.38727155327796936),\n",
      "    ('Akıllı Ol', 0.38670727610588074),\n",
      "    ('Kayıp Savaş', 0.3865184187889099),\n",
      "    ('Görünmez Savaşçı', 0.38609176874160767)]\n",
      "tony stark bir mühendislik dahisi tam bir playboydur kendi ülkesinde teknoloji harikası füzeler silahlar üretmektedir afganistan ’ da yeni bir füzeyi tanıtırken esir düşer yaralanır onu kaçıranlar kendileri bir füze yapmasını isterler tony bunun yerine zırhlı bir giysi yapar bunu yapmaktaki amacı zekasını kullanarak farklı bir kurtuluş yöntemini planlamaktır boş zamanlarını kadınlarına ayıran tony ’ nin hayatı artık tamamen farklı bir şekle bürünmüştür onun bununla baş edeceği esas konudur\n"
     ]
    }
   ],
   "source": [
    "def search_by_tag(tag):\n",
    "    for doc in tagged_data:\n",
    "        if doc.tags[0] == tag:\n",
    "            return \" \".join(doc.words)\n",
    "\n",
    "def return_most_similar(mov_title) -> list:\n",
    "  tokens = remove_html(remove_punctuation(remove_stop_words(make_lower_case(search_by_tag(mov_title))))).split()\n",
    "  vector = model_dbow.infer_vector(tokens)\n",
    "  most_similar = model_dbow.dv.most_similar([vector], topn=20) \n",
    "  return most_similar\n",
    "\n",
    "def return_token(mov_title) -> list:\n",
    "  tokens = remove_html(remove_punctuation(remove_stop_words(make_lower_case(search_by_tag(mov_title))))).split()\n",
    "  return tokens\n",
    "\n",
    "def return_most_similar_token(vec) -> list:\n",
    "  # len(df_final['Title']\n",
    "  most_similar = model_dbow.dv.most_similar([vec],topn=20)\n",
    "  return most_similar\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "seed_text = 'Iron Man'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)\n",
    "print(search_by_tag(seed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Dune:Çöl Gezegeni', 0.9543482065200806),\n",
      "    ('Dune', 0.45587852597236633),\n",
      "    ('House Of Re-Animator', 0.4497130811214447),\n",
      "    ('Dune: Part Two', 0.4394340515136719),\n",
      "    ('Vampir İmparatorluğu', 0.4189107418060303),\n",
      "    ('Bride Of Frankenstein', 0.4171842932701111),\n",
      "    ('Cesur Horoz', 0.41203776001930237),\n",
      "    ('Before We Vanish', 0.39964598417282104),\n",
      "    ('Cabin Fever', 0.39545121788978577),\n",
      "    ('Khers nist', 0.3914357125759125),\n",
      "    ('Avatar 5', 0.38993018865585327),\n",
      "    ('Xin long men ke zhan', 0.38973021507263184),\n",
      "    ('Kaptan Harlock', 0.388936311006546),\n",
      "    ('Resident Evil 5: İntikam', 0.38832470774650574),\n",
      "    ('Tanrının Kitabi', 0.38437628746032715),\n",
      "    ('Casuslar Köprüsü', 0.3836266100406647),\n",
      "    ('The Caine Mutiny Court-Martial', 0.3832657039165497),\n",
      "    ('28 Gün Sonra', 0.3817640542984009),\n",
      "    ('Ant-Man ve Wasp: Quantumania', 0.3809562921524048),\n",
      "    ('Star Wars: Güç Uyanıyor', 0.38010355830192566)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Dune:Çöl Gezegeni'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Yüzüklerin Efendisi: İki Kule', 0.9500899910926819),\n",
      "    ('Pearl Harbor', 0.47223082184791565),\n",
      "    ('Gelibolu', 0.4592815935611725),\n",
      "    ('King Kong vs. Godzilla', 0.4275374710559845),\n",
      "    ('The Lord Of The Rings: The War Of Rohirrim', 0.4228450357913971),\n",
      "    ('Hobbit: Beş Ordunun Savaşı', 0.41768234968185425),\n",
      "    ('Uzay Yolu IV', 0.4161980152130127),\n",
      "    ('Murder in the First', 0.4150218665599823),\n",
      "    ('Harry Potter ve Ateş Kadehi', 0.4138086140155792),\n",
      "    ('The Big Black', 0.41283881664276123),\n",
      "    ('Gezgin Pantolon Kardeşliği 2', 0.4121832847595215),\n",
      "    ('Pers Prensi: Zamanın Kumları', 0.40483254194259644),\n",
      "    ('The Day It Came to Earth', 0.39698025584220886),\n",
      "    ('Skinwalkers', 0.3954154849052429),\n",
      "    ('Da Vinci Şifresi', 0.3941201865673065),\n",
      "    ('Rescue Dawn', 0.39369285106658936),\n",
      "    ('Under sandet', 0.3923293650150299),\n",
      "    (\"Mortal Kombat Legends : Scorpion's Revenge\", 0.39112597703933716),\n",
      "    ('Üçkağıtçı', 0.39096465706825256),\n",
      "    ('Studio 54', 0.3909226655960083)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Yüzüklerin Efendisi: İki Kule'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Rashômon', 0.9476543664932251),\n",
      "    ('Françoise ou la vie conjugale', 0.5435649156570435),\n",
      "    ('İntikam Meleği/Kadın Hamlet', 0.5181604027748108),\n",
      "    ('Gölgeler ve Sis', 0.4887164831161499),\n",
      "    ('Seules Les Bêtes', 0.4784468710422516),\n",
      "    ('Deathstalker', 0.4713344871997833),\n",
      "    ('Münferit', 0.4707236588001251),\n",
      "    ('Ölüm Gemisi', 0.4622574746608734),\n",
      "    ('Parçalanma', 0.46023598313331604),\n",
      "    ('Kanlı Feryad', 0.458997517824173),\n",
      "    (\"Fatmagül'ün Suçu Ne?\", 0.4543512165546417),\n",
      "    ('Korkunç Orakçı', 0.45266059041023254),\n",
      "    ('Aşk Nöbeti', 0.4518894553184509),\n",
      "    ('Absentia', 0.45114442706108093),\n",
      "    ('Detained', 0.44956687092781067),\n",
      "    ('Kehanet; Ayasofya', 0.44840914011001587),\n",
      "    ('Yılanların Öcü', 0.44721612334251404),\n",
      "    ('De Lift', 0.44244807958602905),\n",
      "    ('Matar a un Muerto', 0.442259818315506),\n",
      "    ('The Exorcist III', 0.44154855608940125)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Rashômon'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('Titanik', 0.9488952159881592),\n",
      "    ('Dinozor', 0.4613831341266632),\n",
      "    ('Beavis and Butt-Head Do the Universe', 0.4197002351284027),\n",
      "    ('The Lord Of The Rings: The War Of Rohirrim', 0.4190202057361603),\n",
      "    ('Last Words', 0.4082288146018982),\n",
      "    ('Anchiporuno', 0.40757089853286743),\n",
      "    ('Apollo 10 1/2: Uzay Çağında Çocuk Olmak', 0.3962409496307373),\n",
      "    ('Nos Futurs', 0.39575523138046265),\n",
      "    ('İyilik ve Kötülük Okulu', 0.39204472303390503),\n",
      "    ('Spider-Man: Beyond The Spider-Verse', 0.38597914576530457),\n",
      "    ('2 Kız', 0.3858177959918976),\n",
      "    ('Frankenstein: Ölümsüzlerin Savaşı', 0.3837279677391052),\n",
      "    ('Cirque du Soleil: Worlds Away', 0.38000935316085815),\n",
      "    ('Shirin', 0.37940600514411926),\n",
      "    ('Booksmart', 0.37793421745300293),\n",
      "    ('2012', 0.37791845202445984),\n",
      "    ('Summer Of 8', 0.3772253394126892),\n",
      "    ('Vic + Flo ont vu un ours', 0.3758023977279663),\n",
      "    ('Pas ve Gol', 0.3735332190990448),\n",
      "    ('Ruh Eşim', 0.3732932507991791)]\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Titanik'\n",
    "x = return_most_similar(seed_text)\n",
    "pp.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dict has title:embedding -> embeddings are created using that specific movie's plot\n",
    "movie_embeddings = {title: model_dbow.infer_vector(return_token(title)) for title in df_final['Title']}\n",
    "\n",
    "with open(\"movie_embed_genre.pickle\", \"wb\") as f:\n",
    "    pickle.dump(movie_embeddings, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining our embeddings and saving them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_embed_desc.pickle', 'rb') as f:\n",
    "    desc = pickle.load(f)\n",
    "with open('movie_embed_genre.pickle', 'rb') as f_1:\n",
    "    other = pickle.load(f_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rank_list(embeds:dict, mov_title:str) -> list:\n",
    "\n",
    "  selected_vector = embeds[mov_title]\n",
    "\n",
    "  similarities = []\n",
    "  for movie_title, vector in embeds.items():\n",
    "      cos_sim = 1 - distance.cosine(selected_vector, vector)\n",
    "      similarities.append((movie_title, cos_sim))\n",
    "\n",
    "  ranked_movies = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "  ranked_movies = [x for x in ranked_movies if x[0] != mov_title]\n",
    "\n",
    "\n",
    "  dct = {}\n",
    "  # replacing cosine similarities with ranks\n",
    "  for index, item in enumerate(ranked_movies):\n",
    "    itemlist = list(item)\n",
    "    # itemlist[1] = index + 1\n",
    "    # item = tuple(itemlist)\n",
    "\n",
    "    # ranked_movies[index] = item\n",
    "\n",
    "    dct[itemlist[0]] = index+1\n",
    "\n",
    "\n",
    "  return dct\n",
    "\n",
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = {}\n",
    "    for title, embedding1 in dict1.items():\n",
    "        embedding2 = dict2[title]\n",
    "        merged_embedding = (embedding1 * 0.7 + embedding2 * 0.3)\n",
    "        merged_dict[title] = merged_embedding\n",
    "    return merged_dict\n",
    "merged_dict = merge_dicts(desc, other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_title = 'Hababam Sınıfı Uyanıyor'\n",
    "closest_movies = return_rank_list(merged_dict, mov_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embeddings/movie_embeddings.pickle\", \"wb\") as f:\n",
    "    pickle.dump(merged_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from scipy.spatial import distance\n",
    "import re\n",
    "from random import shuffle\n",
    "import string\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec    \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import pickle\n",
    "import pprint\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings/movie_embeddings.pickle', 'rb') as f_1:\n",
    "    embeds = pickle.load(f_1)\n",
    "    \n",
    "def return_rank_list(embeds:dict, mov_title:str) -> list:\n",
    "\n",
    "  selected_vector = embeds[mov_title]\n",
    "\n",
    "  similarities = []\n",
    "  for movie_title, vector in embeds.items():\n",
    "      cos_sim = 1 - distance.cosine(selected_vector, vector)\n",
    "      similarities.append((movie_title, cos_sim))\n",
    "\n",
    "  ranked_movies = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "  ranked_movies = [x for x in ranked_movies if x[0] != mov_title]\n",
    "\n",
    "\n",
    "  dct = {}\n",
    "  # replacing cosine similarities with ranks\n",
    "  for index, item in enumerate(ranked_movies):\n",
    "    itemlist = list(item)\n",
    "    # itemlist[1] = index + 1\n",
    "    # item = tuple(itemlist)\n",
    "\n",
    "    # ranked_movies[index] = item\n",
    "\n",
    "    dct[itemlist[0]] = index+1\n",
    "\n",
    "\n",
    "  return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guess_movie = 'Iron Man'\n",
    "# valid_movies = list(embeds.keys())\n",
    "# game = True\n",
    "# sim_movies_list = return_rank_list(embeds,guess_movie)\n",
    "# while game:\n",
    "#     user_input = input()\n",
    "#     if user_input not in valid_movies:\n",
    "#         print('I do not know this movie')\n",
    "#     else:\n",
    "#         if (user_input == guess_movie):\n",
    "#             print('You have won.')\n",
    "#             break\n",
    "#         print(f'{user_input}:{sim_movies_list[user_input]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import customtkinter\n",
    "import tkinter as tk\n",
    "guess_movie = \"Hababam Sınıfı Uyanıyor\"\n",
    "valid_movies = list(embeds.keys())\n",
    "sim_movies_list = return_rank_list(embeds,guess_movie)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 553, in _clicked\n",
      "    self._command()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11340\\45447972.py\", line 31, in check_guess\n",
      "    previous_guesses.append((user_input, sim_movies_list[user_input]))\n",
      "KeyError: 'Recep İvedik 5'\n"
     ]
    }
   ],
   "source": [
    "def main_window():\n",
    "    customtkinter.set_appearance_mode(\"dark\")\n",
    "    customtkinter.set_default_color_theme(\"dark-blue\")\n",
    "\n",
    "    root = customtkinter.CTk()\n",
    "    root.title(\"Movie Guess Game\")\n",
    "    root.geometry(\"650x450\")\n",
    "    frame = customtkinter.CTkFrame(master=root)\n",
    "    frame.pack(pady=15, padx=30, fill=\"both\",expand=True)\n",
    "\n",
    "    label = customtkinter.CTkLabel(frame, text=\"Guess the movie\", font=(\"Helvetica\", 16))\n",
    "    label.pack(pady=15, padx=30, fill=\"both\",expand=True)\n",
    "\n",
    "    guess_entry = customtkinter.CTkEntry(frame, font=(\"Helvetica\", 14))\n",
    "    guess_entry.pack(pady=10)\n",
    "\n",
    "    previous_guesses = []\n",
    "    def game_check(user_input):\n",
    "        if (user_input == guess_movie):\n",
    "            result_label.configure(text=\"You have won. You may close the window.\")\n",
    "            guess_entry.configure(state=\"disabled\")\n",
    "            guess_button.configure(state=\"disabled\")\n",
    "\n",
    "    def check_guess():\n",
    "        user_input = guess_entry.get().strip() \n",
    "        game_check(user_input)    \n",
    "        if user_input not in valid_movies:\n",
    "            result_label.configure(text=\"I do not know this movie\")\n",
    "        else:\n",
    "            game_check(user_input)\n",
    "            previous_guesses.append((user_input, sim_movies_list[user_input]))\n",
    "            previous_guesses.sort(key=lambda x: x[1], reverse=False)\n",
    "            result_label.configure(text=f\"{user_input}:{sim_movies_list[user_input]}\")\n",
    "        previous_guesses_list.delete(0, tk.END)\n",
    "        for guess in previous_guesses:\n",
    "            previous_guesses_list.insert(tk.END, f\"{guess[0]}:{guess[1]}\")\n",
    "\n",
    "    guess_button = customtkinter.CTkButton(frame, text=\"Guess\", command=check_guess, font=(\"Helvetica\", 14))\n",
    "    guess_button.pack(pady=10)\n",
    "\n",
    "    result_label = customtkinter.CTkLabel(master=frame, text=f\"\")\n",
    "    result_label.pack(pady=20)\n",
    "\n",
    "    previous_guesses_label = customtkinter.CTkLabel(frame, text=\"Previous guesses:\", font=(\"Helvetica\", 14))\n",
    "    previous_guesses_label.pack(pady=10)\n",
    "\n",
    "\n",
    "    previous_guesses_list = tk.Listbox(frame, fg = \"white\" ,bg = \"#262629\", font=(\"Helvetica\", 14))\n",
    "    previous_guesses_list.pack(pady=10)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "main_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recep İvedik 3': 1,\n",
       " 'Recep İvedik 4': 2,\n",
       " 'Recep İvedik': 3,\n",
       " 'Recep İvedik 7': 4,\n",
       " 'Recep İvedik 2': 5,\n",
       " 'Osman Pazarlama': 6,\n",
       " 'Celal ile Ceren': 7,\n",
       " 'Recep İvedik 6': 8,\n",
       " 'Kuru Otlar Üstüne': 9,\n",
       " 'Feride': 10,\n",
       " 'Yalancı Şahit': 11,\n",
       " 'Bulutların Üstünde': 12,\n",
       " 'Bayram Şekeri': 13,\n",
       " 'Kayhan': 14,\n",
       " 'Dedemin Fişi': 15,\n",
       " 'Hep Yek 5: Bizim Şeyimiz mi Altan': 16,\n",
       " 'Avanak Dedektör': 17,\n",
       " 'Güvercin Uçuverdi': 18,\n",
       " 'Hep Yek 2': 19,\n",
       " '41 Kere Maşallah': 20,\n",
       " 'Posta Kutusu': 21,\n",
       " \"Abbas'ın Melekleri\": 22,\n",
       " '7 Melek': 23,\n",
       " 'Hep Yek 4: Bela Okuma Altan': 24,\n",
       " 'Leblebi Tozu': 25,\n",
       " 'Öt Bakalım': 26,\n",
       " 'Ölü Yatırım': 27,\n",
       " 'Hep Yek 3': 28,\n",
       " 'Tilki Yuvası': 29,\n",
       " 'Kaygı': 30,\n",
       " 'Zengo': 31,\n",
       " 'Kayseri Aslanı: Çin İşi': 32,\n",
       " 'Eyvah Karım': 33,\n",
       " 'Deliha 2': 34,\n",
       " 'Figüran': 35,\n",
       " 'Baba Mirası': 36,\n",
       " 'Çam Yarması 2': 37,\n",
       " 'Arınma Seansı - Tarot': 38,\n",
       " 'Sağ Salim': 39,\n",
       " 'Aşkın Tadı': 40,\n",
       " 'Muhalif Başkan': 41,\n",
       " 'Kafkas': 42,\n",
       " 'Deli Dumrul': 43,\n",
       " 'Vezir Parmağı': 44,\n",
       " 'Ulan Salih': 45,\n",
       " 'Gülcemal': 46,\n",
       " 'Boğa Boğa': 47,\n",
       " 'Fal': 48,\n",
       " 'Hedefim Sensin': 49,\n",
       " 'Hareket Sekiz': 50,\n",
       " 'Cok Filim Hareketler Bunlar': 51,\n",
       " 'Hiç': 52,\n",
       " 'Tutmayın Beni': 53,\n",
       " 'Nereden Nereye': 54,\n",
       " 'Hayatta Olmaz': 55,\n",
       " 'La Hay De Maske': 56,\n",
       " 'Siccin 4': 57,\n",
       " 'Aşkın 5 Hali': 58,\n",
       " 'Yapışık Kardeşler': 59,\n",
       " 'Karışma Bende': 60,\n",
       " 'Hanzap': 61,\n",
       " 'Mahalle': 62,\n",
       " 'Yanlış Adres': 63,\n",
       " 'Mazi Yarası': 64,\n",
       " 'Prestij Meselesi': 65,\n",
       " 'Ali': 66,\n",
       " 'Çok Aşk': 67,\n",
       " 'Akıllara Seza': 68,\n",
       " 'Cenaze İşleri': 69,\n",
       " 'Hadi Be!': 70,\n",
       " 'Adana İşi': 71,\n",
       " 'Facia Üçlü': 72,\n",
       " 'Meryem': 73,\n",
       " 'Kaç Kaçabilirsen': 74,\n",
       " 'Üç, İki, Bir... Kestik!': 75,\n",
       " 'Mucize Aynalar': 76,\n",
       " 'Bahtiyar Bahtıkara': 77,\n",
       " 'Kar ve Ayı': 78,\n",
       " 'Rahha': 79,\n",
       " 'Karımı Gördünüz Mü?': 80,\n",
       " 'Kariyer': 81,\n",
       " 'Sekar': 82,\n",
       " \"Barcelona'nın Şifresi Temel\": 83,\n",
       " 'Baş Belası': 84,\n",
       " 'Ali Çevlik': 85,\n",
       " '8x8': 86,\n",
       " 'Plaza': 87,\n",
       " 'Zalo': 88,\n",
       " 'Grev': 89,\n",
       " 'Zehşin Cin-i Musallat': 90,\n",
       " 'Sil Baştan Kaynanam': 91,\n",
       " 'Gen': 92,\n",
       " 'Kadınlara Mahsus': 93,\n",
       " 'Hadi İnşallah': 94,\n",
       " 'Zevcat': 95,\n",
       " 'Ferhat Ile Sirin': 96,\n",
       " 'Zerre': 97,\n",
       " 'Mekan': 98,\n",
       " 'Kalp Estetiği': 99,\n",
       " 'Nuh Boğuldu': 100,\n",
       " 'Mahlûkat': 101,\n",
       " 'Karışık Kaset': 102,\n",
       " 'Kars Öyküleri': 103,\n",
       " 'Bahtsız Bedri': 104,\n",
       " 'Mor Ufuklar': 105,\n",
       " 'Deli Aşk': 106,\n",
       " 'Milyonluk Kuş': 107,\n",
       " 'Şevkat Yerimdar 2': 108,\n",
       " 'Poyraz Karayel: Küresel Sermaye': 109,\n",
       " 'Kül': 110,\n",
       " 'Jîn': 111,\n",
       " 'Hep Yek': 112,\n",
       " \"OHA: Oflu Hoca'yı Aramak\": 113,\n",
       " 'Allah Yazdıysa Bozsun': 114,\n",
       " 'Çok Da Tın': 115,\n",
       " \"Oflu Hoca Trakya'da\": 116,\n",
       " 'Tatlım Tatlım': 117,\n",
       " 'Çilingir Sofrası': 118,\n",
       " 'Ustalar Alemi': 119,\n",
       " 'Mihrez 2: Cin Padişahı': 120,\n",
       " \"Hadi Hayırlısı - Istakoz'un Haritası\": 121,\n",
       " 'Üç Günlük Dünya': 122,\n",
       " 'Seni Buldum Ya!': 123,\n",
       " 'Fındık Veresiye': 124,\n",
       " 'Çılgın Kolej': 125,\n",
       " 'Erzurumlu Mümessil': 126,\n",
       " 'Toz Bezi': 127,\n",
       " 'Ahlat Ağacı': 128,\n",
       " 'Bayram Abi': 129,\n",
       " 'Şov Bizınıs': 130,\n",
       " 'Ammar 3: Cin Kabilesi': 131,\n",
       " 'Öfkeli Çılgınlık Karamsar Çile': 132,\n",
       " 'Dabbe 5: Zehr-i Cin': 133,\n",
       " 'Mavi Dalga': 134,\n",
       " 'Bizans Oyunları': 135,\n",
       " 'İşin Aslı': 136,\n",
       " 'Bi O Kalmıştı': 137,\n",
       " 'Bende Kal': 138,\n",
       " 'Ammar 2: Cin İstilası': 139,\n",
       " 'Eyyvah Eyvah 3': 140,\n",
       " 'Seninki Kaç Para?': 141,\n",
       " 'Birkaç Günlük Mola': 142,\n",
       " \"O'nun Hikayesi\": 143,\n",
       " 'Amigos Meksika Hazinesi': 144,\n",
       " 'Azem 2: Cin Garezi': 145,\n",
       " 'Obsesyon': 146,\n",
       " 'Eltilerin Savaşı': 147,\n",
       " 'Sağ Salim 2: Sil Baştan': 148,\n",
       " 'Sorma Neden?': 149,\n",
       " 'Arama Moturu': 150,\n",
       " 'Huzurevi Ketum': 151,\n",
       " 'Doku': 152,\n",
       " 'Ne Olur Gitme': 153,\n",
       " 'Celal Tan ve Ailesinin Aşırı Acıklı Hikayesi': 154,\n",
       " 'Bayrak-1': 155,\n",
       " 'Eyyvah Eyvah': 156,\n",
       " 'Karayel': 157,\n",
       " 'Mahalleden Arkadaşlar': 158,\n",
       " 'Ah Be Birader': 159,\n",
       " 'Petrol Sevdası': 160,\n",
       " 'Dís': 161,\n",
       " 'Bizum Hoca 2': 162,\n",
       " 'Bebek Geliyorum Demez': 163,\n",
       " \"Madımak: Carina'nın Günlüğü\": 164,\n",
       " 'Dedem: Bir Aile Kahramanı': 165,\n",
       " 'Seni Bulacam Oğlum!': 166,\n",
       " 'Çağdaş Bir Köle': 167,\n",
       " 'Eyyvah Eyvah 2': 168,\n",
       " 'Gelin Takımı': 169,\n",
       " 'Adresi Olmayan Ev': 170,\n",
       " 'Ölü Mevsim': 171,\n",
       " 'Vay Başıma Gelenler': 172,\n",
       " 'Saddamın Askerleri': 173,\n",
       " 'Şahıs 46': 174,\n",
       " 'Yolun Açık Olsun': 175,\n",
       " 'Yanlış Anlama': 176,\n",
       " 'Hayalet Dayı': 177,\n",
       " 'Saftirikler': 178,\n",
       " 'Öyle ya da Böyle': 179,\n",
       " 'Parayı Bulduk': 180,\n",
       " 'Propaganda 2': 181,\n",
       " '5 Dakkada Değişir Bütün İşler': 182,\n",
       " 'Cin-si Bozuk': 183,\n",
       " 'Cennetten Kovulmak': 184,\n",
       " 'Plajda': 185,\n",
       " 'Şipşak Anadolu': 186,\n",
       " 'Fırıncının Karısı': 187,\n",
       " 'Hırs': 188,\n",
       " 'Serseriler': 189,\n",
       " 'Cumali Ceber 666': 190,\n",
       " 'Hadim': 191,\n",
       " 'Şevkat Yerimdar': 192,\n",
       " 'Ver Kaç': 193,\n",
       " 'Sinyalciler': 194,\n",
       " 'Âdem': 195,\n",
       " 'Sera': 196,\n",
       " \"Selim Bey'in Yolculuğu\": 197,\n",
       " \"Sümela'nın Şifresi Temel\": 198,\n",
       " 'Organik Aşk Hikayeleri': 199,\n",
       " 'Çocuklar Sana Emanet': 200,\n",
       " 'Devrim Arabaları': 201,\n",
       " 'Güneşi Gördüm': 202,\n",
       " 'Bekar Bekir': 203,\n",
       " 'Kolonya Cumhuriyeti': 204,\n",
       " 'Yola Çıkmak': 205,\n",
       " 'Mefruh: Vahşeti Cin': 206,\n",
       " 'Kurtlar ve Çakallar': 207,\n",
       " 'Yarına Tek Bilet': 208,\n",
       " 'Guruldayan Kalpler': 209,\n",
       " 'Her Şey Dahil': 210,\n",
       " 'Rüzgarın Hatıraları': 211,\n",
       " 'Deccal': 212,\n",
       " 'Şeflerin Şefi': 213,\n",
       " 'Deliha': 214,\n",
       " 'Hükümet Kadın': 215,\n",
       " 'Büşra': 216,\n",
       " 'Keşfedilmemiş Çocuklar': 217,\n",
       " 'Kaşık': 218,\n",
       " 'Aşkın Saati 19.03': 219,\n",
       " 'Benzersiz': 220,\n",
       " 'Kazak İşi Türkiye’de': 221,\n",
       " 'Siccin 5': 222,\n",
       " 'Yıldızlar da Kayar': 223,\n",
       " 'Meleklerin Mucizesi': 224,\n",
       " 'Kor': 225,\n",
       " 'Piano Piano Bacaksız': 226,\n",
       " 'Sen Sağ Ben Selamet': 227,\n",
       " 'Devir': 228,\n",
       " 'Vazgeçme': 229,\n",
       " 'Gizemli Köy': 230,\n",
       " 'İşe Yarar Bir Şey': 231,\n",
       " 'Ağır Romantik': 232,\n",
       " 'Babamın Kanatları': 233,\n",
       " 'Musallat 3': 234,\n",
       " '9,75': 235,\n",
       " 'Olaylar Olaylar': 236,\n",
       " 'Çekmeceler': 237,\n",
       " 'Azem 4: Alacakaranlık': 238,\n",
       " 'Roza': 239,\n",
       " 'İlişki Doktoru': 240,\n",
       " 'Çarşı Pazar': 241,\n",
       " 'Buğday Tanesi': 242,\n",
       " 'Aşk Uykusu': 243,\n",
       " 'Bizum Uşaklar': 244,\n",
       " 'Rüya': 245,\n",
       " 'Oha Diyorum': 246,\n",
       " 'Nasipse Adayız': 247,\n",
       " 'Cin Tepesi': 248,\n",
       " 'Hayvan': 249,\n",
       " 'Öz Hakiki Karakol': 250,\n",
       " 'Terkedilmiş': 251,\n",
       " 'Istanbul Story': 252,\n",
       " 'Sahir Deep Web': 253,\n",
       " 'Sokak Sınıfı': 254,\n",
       " 'Kaygısız Baş': 255,\n",
       " 'Aslan Parçam': 256,\n",
       " 'Aden': 257,\n",
       " 'Hızlı ve Tüplü': 258,\n",
       " 'Kafir': 259,\n",
       " 'Bittin Sen': 260,\n",
       " 'Güzel Günler Göreceğiz': 261,\n",
       " 'Müstakbel Damat': 262,\n",
       " 'Tuzdan Kaide': 263,\n",
       " 'Ecinni: Tılsımlı Mezar': 264,\n",
       " 'Narayama Bushiko': 265,\n",
       " 'Kuşatma Yedi Uyuyanlar': 266,\n",
       " 'İki Çizgi': 267,\n",
       " 'Aah Güzel İstanbul': 268,\n",
       " 'Rem': 269,\n",
       " 'Hababam Sınıfı Yeniden': 270,\n",
       " 'SIFIR: Etkisiz Eleman': 271,\n",
       " 'Firak': 272,\n",
       " 'Paranoid': 273,\n",
       " '40m2 Almanya': 274,\n",
       " 'Son Haber': 275,\n",
       " 'Git Başımdan': 276,\n",
       " 'Polis Akademisi: Alaturka': 277,\n",
       " 'Iklimler': 278,\n",
       " 'Babamın Kemikleri': 279,\n",
       " 'Mustang': 280,\n",
       " 'Rauf': 281,\n",
       " 'Kestik Babacım': 282,\n",
       " 'Acemi Hırsız': 283,\n",
       " 'Cemil Şov': 284,\n",
       " 'Yönetmen': 285,\n",
       " 'Evlad-ı Cin': 286,\n",
       " 'Sadakat': 287,\n",
       " 'Poşetten Kanatlar': 288,\n",
       " 'Haris': 289,\n",
       " 'Martı': 290,\n",
       " 'Mutlu Aile Tablosu': 291,\n",
       " 'Toz': 292,\n",
       " \"BABA 'Bu Alem Bi Alem'\": 293,\n",
       " 'Yok Artık! 2': 294,\n",
       " 'Dalavere': 295,\n",
       " 'Şeytanın Çocukları-El Ebyaz': 296,\n",
       " '8 (Sekiz)': 297,\n",
       " 'Niyazi Gül Dört Nala': 298,\n",
       " 'Bordo Bereliler Afrin': 299,\n",
       " 'Hükümet Kadın 2': 300,\n",
       " 'Büyü 2': 301,\n",
       " 'Gitme Baba': 302,\n",
       " 'Merdiven Baba': 303,\n",
       " 'Avrupalı': 304,\n",
       " 'Belik': 305,\n",
       " 'Anadolu Leoparı': 306,\n",
       " 'Olur Olur!': 307,\n",
       " 'Alem-i Cin 3: Salgın': 308,\n",
       " \"Zeynep'in Sekiz Günü\": 309,\n",
       " 'Psişik': 310,\n",
       " 'Kız Kardeşler': 311,\n",
       " 'Oğlan Bizim Kız Bizim': 312,\n",
       " 'Mavi Pansiyon': 313,\n",
       " 'Benimle Var Mısın?': 314,\n",
       " 'Fazilet': 315,\n",
       " 'Çakallarla Dans 6': 316,\n",
       " 'Cin Kuyusu': 317,\n",
       " 'Toz Ruhu': 318,\n",
       " 'Samet Hergün': 319,\n",
       " 'Kutsal Damacana 4': 320,\n",
       " 'Her Şey Aşktan': 321,\n",
       " 'Dua Et Kardeşiz': 322,\n",
       " 'Melekleri Taşıyan Adam': 323,\n",
       " 'Eksik Sayfalar': 324,\n",
       " 'Çam Yarması': 325,\n",
       " 'Küçük Şeyler': 326,\n",
       " 'Yeniden Leyla': 327,\n",
       " 'Sen Kiminle Dans Ediyorsun?': 328,\n",
       " 'Yürügari İbram': 329,\n",
       " 'Marid': 330,\n",
       " 'Nezih Bir Film': 331,\n",
       " 'Benim Adım Feridun': 332,\n",
       " 'Umut Apartmanı': 333,\n",
       " 'Baba 1.5': 334,\n",
       " 'Miraç': 335,\n",
       " 'Selam: Bahara Yolculuk': 336,\n",
       " 'Kako si?': 337,\n",
       " 'Hicran ve Melek': 338,\n",
       " 'Hayalimdeki Köy': 339,\n",
       " 'Semur 3: Kıyamet-i Cin': 340,\n",
       " 'Ne Çıkarsa Bahtına Gari': 341,\n",
       " 'Şeytan-ı Racim 2: İfrit': 342,\n",
       " 'Çamur': 343,\n",
       " 'Kronoloji': 344,\n",
       " 'Balık': 345,\n",
       " 'Cehennem 3D': 346,\n",
       " 'Sarmaşık': 347,\n",
       " 'Kız Kardeşim Mommo': 348,\n",
       " '7. Koğuştaki Mucize': 349,\n",
       " 'Güvercin': 350,\n",
       " 'Tamam mıyız?': 351,\n",
       " 'Cin Perdesi': 352,\n",
       " 'Son Seans: MTTH': 353,\n",
       " 'Saç': 354,\n",
       " 'Kağıt': 355,\n",
       " 'Dalgalar ve İzler': 356,\n",
       " 'Yağmurlu Gecede Gülperi': 357,\n",
       " 'Operasyon': 358,\n",
       " 'Üç Maymun': 359,\n",
       " 'Düşeş 1 - Mafya Sızıntısı': 360,\n",
       " \"Sümela'nın Şifresi 3: Cünyor Temel\": 361,\n",
       " 'Karakomik Filmler': 362,\n",
       " 'Piyasadan Büyük Alacağımız Var': 363,\n",
       " 'Cici Babam': 364,\n",
       " \"Topal Şükran'ın Maceraları\": 365,\n",
       " 'Cumali Ceber 2': 366,\n",
       " 'Neredesin Firuze': 367,\n",
       " 'Kasap Havası': 368,\n",
       " 'Görümce': 369,\n",
       " 'Aşkın Kıyameti': 370,\n",
       " 'Aykut Enişte 2': 371,\n",
       " 'Dabbe 2': 372,\n",
       " 'Süper İncir': 373,\n",
       " 'Amacı Olmayan Grup': 374,\n",
       " 'Aşk Oluversin Gari': 375,\n",
       " 'Gerçek Cinler': 376,\n",
       " 'El Yazısı': 377,\n",
       " 'Kavşak': 378,\n",
       " 'Hara': 379,\n",
       " 'Nokta': 380,\n",
       " 'Turist Ömer Dümenciler Kralı': 381,\n",
       " 'Şerr-i Cin': 382,\n",
       " 'Yanlış Zaman Yolcuları': 383,\n",
       " 'Çalgı Çengi İkimiz (Çalgı Çengi 2)': 384,\n",
       " 'Kar Kırmızı': 385,\n",
       " 'Aşk Ağlatır': 386,\n",
       " 'Ali Kundilli': 387,\n",
       " \"Asmoday: Cin'ur Racim\": 388,\n",
       " 'Kaybedenler Kulübü Yolda': 389,\n",
       " 'Son Çıkış': 390,\n",
       " 'Khers nist': 391,\n",
       " 'F Tipi Film': 392,\n",
       " 'Tesis': 393,\n",
       " 'Döngel Kârhanesi': 394,\n",
       " 'Pilavüstü Aşk': 395,\n",
       " 'Yemekteydik ve Karar Verdim': 396,\n",
       " 'Türk Lokumu': 397,\n",
       " 'Sinsi': 398,\n",
       " 'Oyuncak Tabanca': 399,\n",
       " 'Gazap': 400,\n",
       " 'Üç Harfliler 3: Karabüyü': 401,\n",
       " 'Çakma Hayat': 402,\n",
       " 'Astral Seyahat': 403,\n",
       " 'Vay Halime': 404,\n",
       " 'Zehr-i Azap': 405,\n",
       " 'Dümdüzz Adam': 406,\n",
       " \"Temel ile Dursun İstanbul'da\": 407,\n",
       " 'Cici': 408,\n",
       " 'Akıl Bozan': 409,\n",
       " '7 - Yedi': 410,\n",
       " 'Zir-i Cin': 411,\n",
       " 'Dabbe : Cin Çarpması': 412,\n",
       " '7 Kocalı Hürmüz': 413,\n",
       " 'Sivaslıyıh Gardaş': 414,\n",
       " 'Geçen Yaz': 415,\n",
       " 'Beni Sev': 416,\n",
       " 'Vesvese: Cin Fısıltısı': 417,\n",
       " 'Layla M.': 418,\n",
       " 'Şeytan Bunun Neresinde?': 419,\n",
       " 'Aşk Yolunda': 420,\n",
       " 'Kafes': 421,\n",
       " 'Mevsim Çiçek Açtı': 422,\n",
       " 'Benim Kocam Yapmaz': 423,\n",
       " 'Krallar Kulübü': 424,\n",
       " 'Alamet-i Kıyamet': 425,\n",
       " 'Lanetli Anahtar': 426,\n",
       " 'Sir-Ayet: Ölü Doğan': 427,\n",
       " 'Eróticas Profissionais': 428,\n",
       " 'Memlekette Demokrasi Var': 429,\n",
       " 'İyi Biri': 430,\n",
       " 'Babil-i Cin': 431,\n",
       " 'İz (Reç)': 432,\n",
       " 'Tebessüm': 433,\n",
       " 'Lietli: Cin Kabilesi': 434,\n",
       " 'Turist Ömer Arabistan’da': 435,\n",
       " 'Okul Tıraşı': 436,\n",
       " 'Beni Çok Sev': 437,\n",
       " 'Araf 5: Aile': 438,\n",
       " 'O İş Bende': 439,\n",
       " 'Ekisporter': 440,\n",
       " 'Yolunda A.Ş. Çinçin Bağları': 441,\n",
       " 'Netekim Karakolu': 442,\n",
       " 'Limonata': 443,\n",
       " 'Hazep': 444,\n",
       " 'Made in Europe': 445,\n",
       " 'Deliormanlı': 446,\n",
       " 'Şarkıcı': 447,\n",
       " 'Kırıntılar': 448,\n",
       " 'Kaçma Birader': 449,\n",
       " 'Mar': 450,\n",
       " 'Jecão... Um Fofoqueiro no Céu': 451,\n",
       " \"N'apcaz Şimdi?\": 452,\n",
       " 'Çırak': 453,\n",
       " 'Mühr-ü Cin': 454,\n",
       " 'Ma-Şer': 455,\n",
       " 'Halil': 456,\n",
       " \"Moskova'nın Şifresi: Temel\": 457,\n",
       " 'Ateşteki Kağıtlar': 458,\n",
       " 'Kız Meselesi': 459,\n",
       " 'Ali Kundilli 2': 460,\n",
       " 'Sabit Kanca 2': 461,\n",
       " \"Entelköy Efeköy'e Karşı\": 462,\n",
       " 'Sonbahara Doğru': 463,\n",
       " 'Simbiyotik': 464,\n",
       " 'Mukavemet': 465,\n",
       " 'Senarist': 466,\n",
       " 'Öldüm Bittim': 467,\n",
       " 'Geniş Aile 2: Her Türlü': 468,\n",
       " 'Alem-i Cin': 469,\n",
       " '4N1K': 470,\n",
       " 'MandırANA': 471,\n",
       " 'Çınar': 472,\n",
       " 'Kasaba': 473,\n",
       " 'Benim Kendi Hayatım': 474,\n",
       " 'Ara': 475,\n",
       " 'İki': 476,\n",
       " 'Metropol Kabusu': 477,\n",
       " 'Mc Dandik': 478,\n",
       " 'Efsunlu Ayin': 479,\n",
       " 'Saygı': 480,\n",
       " 'Tam Kafadan Karavana': 481,\n",
       " 'Olur İnşallah': 482,\n",
       " 'Gayış': 483,\n",
       " 'Mayıs Sıkıntısı': 484,\n",
       " 'Koğuş Akademisi': 485,\n",
       " 'Kıyıdakiler': 486,\n",
       " 'Seni Gidi Seni': 487,\n",
       " 'Emicem Hospital': 488,\n",
       " 'Deli Kazım': 489,\n",
       " '9 Kere Leyla': 490,\n",
       " 'Hapşuu': 491,\n",
       " 'Aydede': 492,\n",
       " 'Siddah': 493,\n",
       " '40': 494,\n",
       " 'Düğüm Salonu': 495,\n",
       " 'Sabit Kanca': 496,\n",
       " '49': 497,\n",
       " 'Locman': 498,\n",
       " 'Asimetrik': 499,\n",
       " 'Kitap 1820': 500,\n",
       " 'The Yetimler': 501,\n",
       " 'Çilekli Pasta': 502,\n",
       " 'Harbi Define': 503,\n",
       " 'Berzah: Cin Alemi': 504,\n",
       " \"Gürbüz: Hadi Allah'a Emanet\": 505,\n",
       " 'Şansımı Seveyim': 506,\n",
       " 'Ecinni 3: Issız Çığlık': 507,\n",
       " 'Canavar Gibi: Türk İşi Frankeştayn': 508,\n",
       " 'Söz Vermiştin': 509,\n",
       " 'Horoz Bayram': 510,\n",
       " 'İsmetse Olur': 511,\n",
       " 'Acı Gönül': 512,\n",
       " 'Albatrosun Yolculuğu': 513,\n",
       " 'Demir Kadın: Neslican': 514,\n",
       " 'Alemde Bir Gece': 515,\n",
       " 'Malazgirt 1071': 516,\n",
       " 'Humraz Cin Tarikatı': 517,\n",
       " 'Pişt': 518,\n",
       " 'Felak': 519,\n",
       " 'Mini Fenomen': 520,\n",
       " 'Cin Bebek 2': 521,\n",
       " 'Bambaşka': 522,\n",
       " 'Cumali Ceber: Allah Seni Alsın': 523,\n",
       " 'Ortadirek Saban': 524,\n",
       " 'Yola Geldik': 525,\n",
       " 'Ali Baba ve 7 Cüceler': 526,\n",
       " 'Anamız Var 2': 527,\n",
       " 'Saklı Hayatlar': 528,\n",
       " 'Mircin': 529,\n",
       " 'Nadide Hayat': 530,\n",
       " 'Martılar Açken': 531,\n",
       " 'Kutsal Damacana 2: İtmen': 532,\n",
       " 'Babası': 533,\n",
       " 'Erkek Tarafı Testosteron': 534,\n",
       " 'Baskın: Karabasan': 535,\n",
       " 'Gelmeyen Bahar': 536,\n",
       " 'Şeytan Tüyü': 537,\n",
       " 'Muallim': 538,\n",
       " 'Vay Başıma Gelenler! 2 Buçuk': 539,\n",
       " 'Evlenmeden Olmaz': 540,\n",
       " 'Bana Masal Anlatma': 541,\n",
       " 'Arekalar': 542,\n",
       " 'Ben Böyle Şansın': 543,\n",
       " 'Tek Yürek İmalat-ı Harbiye': 544,\n",
       " 'Deli Deli Küpeli': 545,\n",
       " 'Dersaadet Apartmanı': 546,\n",
       " 'Karışık Pizza': 547,\n",
       " 'Bursa Bülbülü': 548,\n",
       " 'Beyza’nın Kadınları': 549,\n",
       " 'Mühr-ü Musallat - Perihan': 550,\n",
       " 'Kedi Özledi': 551,\n",
       " 'Karakomik Filmler 2': 552,\n",
       " 'Bomboş': 553,\n",
       " 'Hayati Tehlike': 554,\n",
       " 'Köyden İndim Şehire': 555,\n",
       " 'Hashtag': 556,\n",
       " 'İblis Karanlığın Sahibi 2': 557,\n",
       " 'Dar Elbise': 558,\n",
       " 'Naz Evi': 559,\n",
       " 'Lantouri': 560,\n",
       " 'Ecinni': 561,\n",
       " 'Kolpaçino': 562,\n",
       " 'Tez: 13. Gece': 563,\n",
       " 'Hadi Be Oğlum': 564,\n",
       " 'Göktaşı': 565,\n",
       " 'Zincirbozan': 566,\n",
       " 'Kaos': 567,\n",
       " 'SüperTürk': 568,\n",
       " 'Fazla Şaapma': 569,\n",
       " 'Dikmen Yıldızı': 570,\n",
       " 'Cin-i Ayet': 571,\n",
       " 'Enkaz': 572,\n",
       " 'Ümmü Sübyan': 573,\n",
       " 'Pamuk Prens': 574,\n",
       " 'Zoraki Misafir': 575,\n",
       " 'Siccin': 576,\n",
       " 'Soma 301': 577,\n",
       " 'Bayrak - 2': 578,\n",
       " 'Prangalı Yarim': 579,\n",
       " 'Dabbe': 580,\n",
       " 'Kimya': 581,\n",
       " 'Tatil Kitabi': 582,\n",
       " 'Demir Kapı': 583,\n",
       " 'Kocan Kadar Konuş: Diriliş': 584,\n",
       " 'Son': 585,\n",
       " 'Emret Komutanım: Şah Mat': 586,\n",
       " 'Türkler Çıldırmış Olmalı': 587,\n",
       " 'Saklı Yüzler: Bosna': 588,\n",
       " 'Düğün Dernek 2: Sünnet': 589,\n",
       " 'Saklambaç: Ölüm Oyunu': 590,\n",
       " 'Ziyaretçi': 591,\n",
       " 'Damat Takımı': 592,\n",
       " 'Kurak Günler': 593,\n",
       " 'Kar': 594,\n",
       " 'Sol Alegria': 595,\n",
       " 'İçimdeki Ses': 596,\n",
       " 'Şafakla Dönenler': 597,\n",
       " 'Yolsuzlar Çetesi': 598,\n",
       " 'Neva': 599,\n",
       " 'Sofra Sırları': 600,\n",
       " 'Alem-i Cin 2': 601,\n",
       " 'In Between Dying': 602,\n",
       " 'Yıldızlar da Kayar - Das Borak': 603,\n",
       " 'Kutsal Damacana 3 Dracoola': 604,\n",
       " 'Gece Gelenler': 605,\n",
       " 'Van Gölü Canavarı': 606,\n",
       " 'Benden Ne Olur?': 607,\n",
       " 'Kozmik Sır DNA': 608,\n",
       " 'Aşk, Büyü, vs.': 609,\n",
       " 'Ay Büyürken Uyuyamam': 610,\n",
       " 'Rina': 611,\n",
       " \"Cumhurbaşkanı Öteki Türkiye'de\": 612,\n",
       " 'No Ofsayt': 613,\n",
       " 'Siccin 3: Cürmü Aşk': 614,\n",
       " 'Uçuş 811': 615,\n",
       " 'Sen İnandır': 616,\n",
       " 'Yusuf Yusuf': 617,\n",
       " 'Mavzer': 618,\n",
       " 'Çakallarla Dans 4': 619,\n",
       " 'Özel Ders': 620,\n",
       " 'Paşa Kızı': 621,\n",
       " \"Korkacak Bi'şey Yok\": 622,\n",
       " 'Arise': 623,\n",
       " 'Sen Benim Herşeyimsin': 624,\n",
       " 'Şeytanın Kitabı': 625,\n",
       " \"Vatikan'ın Şifresi: Bir Temel Macerası\": 626,\n",
       " 'Yol Arkadaşım': 627,\n",
       " 'Lacivert Gece': 628,\n",
       " 'Aşk ve Devrim': 629,\n",
       " 'Görevimiz Tatil': 630,\n",
       " 'Gasp': 631,\n",
       " 'Çoğunluk': 632,\n",
       " 'Hile Yolu': 633,\n",
       " 'Lal': 634,\n",
       " 'Fabrika': 635,\n",
       " 'Kaç Para Kaç': 636,\n",
       " 'Araf': 637,\n",
       " 'Üç Harfliler: Beddua': 638,\n",
       " 'Rus Bebeği': 639,\n",
       " 'Sardunya': 640,\n",
       " 'Elokuu': 641,\n",
       " 'Eğreti Gelin Ladik': 642,\n",
       " 'Bendeyar': 643,\n",
       " 'Mazlum Kuzey & Kuddusi 2: La! Kasada Para Var!': 644,\n",
       " '91.1': 645,\n",
       " \"Oflu Hoca'nın Şifresi\": 646,\n",
       " 'İllet': 647,\n",
       " 'Afetname': 648,\n",
       " 'Cenneti Beklerken': 649,\n",
       " 'Çılgın Dersane 3': 650,\n",
       " 'Rüzgar': 651,\n",
       " 'Babam Büfe': 652,\n",
       " 'Filler ve Çimen': 653,\n",
       " 'Benimle Oynar mısın?': 654,\n",
       " 'İçimdeki Hazine': 655,\n",
       " 'Vallahi Hortladı': 656,\n",
       " 'Zer': 657,\n",
       " 'Çok Filim Hareketler Bunlar': 658,\n",
       " 'İtirazım Var': 659,\n",
       " 'Ju-on': 660,\n",
       " 'Kocan Kadar Konuş': 661,\n",
       " 'Kış Uykusu': 662,\n",
       " 'Metruk': 663,\n",
       " 'Azazil: Düğüm': 664,\n",
       " 'Küf': 665,\n",
       " 'Hakikat Şeyh Bedreddin': 666,\n",
       " 'İçerdekiler': 667,\n",
       " 'Pause': 668,\n",
       " 'Babaların Babası': 669,\n",
       " 'Osman Sekiz': 670,\n",
       " 'Paralı Asker - Musul': 671,\n",
       " 'Rüzgarda Salınan Nilüfer': 672,\n",
       " 'Körfez': 673,\n",
       " 'Baba Parası': 674,\n",
       " 'Mendilim Kekik Kokuyor': 675,\n",
       " 'Hititya : Madalyonun Sırrı': 676,\n",
       " 'Şöhret Tutkusu': 677,\n",
       " 'Kelebekler': 678,\n",
       " 'Hababam Sınıfı Askerde': 679,\n",
       " 'Burçlar': 680,\n",
       " 'Çetin Ceviz': 681,\n",
       " 'Kız Kulesi Aşıkları / Hera İle Leandros': 682,\n",
       " 'bi küçük Eylül meselesi': 683,\n",
       " 'İki Gönül Bir Oluversin Gari': 684,\n",
       " 'Kanal-İ-Zasyon': 685,\n",
       " 'Lanet: Ervah Cinleri': 686,\n",
       " 'Olanlar Oldu': 687,\n",
       " 'Tut Yüreğimden Anne': 688,\n",
       " 'Vizontele Tuuba': 689,\n",
       " 'Geçerken Uğradım': 690,\n",
       " 'Geçmişteki Sır': 691,\n",
       " 'Bembeyaz': 692,\n",
       " 'Otoko no monshô: Ryûko mujô': 693,\n",
       " 'Dilsiz': 694,\n",
       " 'İblis: Karanlığın Sahibi': 695,\n",
       " 'Çilek': 696,\n",
       " 'Zehirli Tohumlar: Ölüm Yolu': 697,\n",
       " 'Ürperti': 698,\n",
       " 'Üç Harfliler: Adak': 699,\n",
       " 'Iblis: Esir-i Beden': 700,\n",
       " 'Ekşi Elmalar': 701,\n",
       " 'Bayrampaşa Ben Fazla Kalmayacağım': 702,\n",
       " 'Köşk-ü Ammar': 703,\n",
       " 'İçimdeki Varlık': 704,\n",
       " 'Aile Hükümeti': 705,\n",
       " 'No: 26 Ölüm Çığlığı': 706,\n",
       " 'Kim Bu Aile?': 707,\n",
       " 'Gen 2: Kurban': 708,\n",
       " 'Baba Nerdesin Kayboldum': 709,\n",
       " 'Çirkin Şansı': 710,\n",
       " 'Oğlum Bak Git': 711,\n",
       " 'Bana Adını Sor': 712,\n",
       " 'Unutursam Fısılda': 713,\n",
       " 'Aşk Olsun': 714,\n",
       " 'Aynasız Haluk': 715,\n",
       " 'Mendirek': 716,\n",
       " 'Flaşbellek': 717,\n",
       " 'Turist Ömer': 718,\n",
       " 'Gece Seansı': 719,\n",
       " 'Af': 720,\n",
       " 'Saf': 721,\n",
       " 'Araf 3: Cinler Kitabı': 722,\n",
       " 'Geniş Aile: Yapıştır!': 723,\n",
       " 'Neden Tarkovski Olamıyorum...': 724,\n",
       " 'Son Şaka': 725,\n",
       " 'Ya Nasip Ya Kısmet': 726,\n",
       " 'Biz Size Döneriz': 727,\n",
       " 'Mardan': 728,\n",
       " 'Mühürlü Köşk': 729,\n",
       " 'İki Şafak Arasında': 730,\n",
       " 'Hadi Ya': 731,\n",
       " 'Bir Şey Değilim': 732,\n",
       " 'Mezeci Çırağı': 733,\n",
       " 'Azazil 2: Büyü': 734,\n",
       " 'Siccin 2': 735,\n",
       " 'Tersine': 736,\n",
       " 'O Şimdi Mahkum': 737,\n",
       " 'O Şimdi Asker': 738,\n",
       " 'Âkif': 739,\n",
       " 'Detay': 740,\n",
       " 'Süper Ajan K9': 741,\n",
       " 'Bekarlığa Feda': 742,\n",
       " 'Enes Batur Hayal Mi Gerçek Mi?': 743,\n",
       " 'Sharqiya': 744,\n",
       " 'İçimdeki Çember': 745,\n",
       " 'Kanat : Vecihi Hürkuş': 746,\n",
       " 'Enes Batur Gerçek Kahraman': 747,\n",
       " 'Mavi Sessizlik': 748,\n",
       " 'Gulyabani': 749,\n",
       " 'Öksüz Kız': 750,\n",
       " 'Azaim: Cin Mezarlığı': 751,\n",
       " 'Yangın Var': 752,\n",
       " 'Zefir': 753,\n",
       " 'Babamın Kemanı': 754,\n",
       " 'Düş Peşine': 755,\n",
       " 'Sarı Köpeğin Yuvası': 756,\n",
       " 'Göç Yolu (Elveda Balkanlar)': 757,\n",
       " 'Aniden': 758,\n",
       " 'Sivil': 759,\n",
       " 'Sir-Ayet': 760,\n",
       " 'Patron Mutlu Son İstiyor': 761,\n",
       " 'Kôsatsu': 762,\n",
       " 'Şeytanı Ararken': 763,\n",
       " 'Kırlangıçlar Susamışsa': 764,\n",
       " 'Nefrin': 765,\n",
       " 'Üç Vakte Kadar': 766,\n",
       " 'Âşıklar Bayramı': 767,\n",
       " '11': 768,\n",
       " 'Annemin Yarası': 769,\n",
       " 'Aşk Nerede?': 770,\n",
       " 'Yüz Numarali Adam': 771,\n",
       " 'Bekçiler Kralı': 772,\n",
       " 'Ya Sonra': 773,\n",
       " \"Hüddam'ın Soyu: Marid Cinleri\": 774,\n",
       " 'Merhaba Güzel Vatanım': 775,\n",
       " 'LCV (Lütfen Cevap Veriniz)': 776,\n",
       " '4N1K 2': 777,\n",
       " 'Rec 4: Kıyamet Gecesi': 778,\n",
       " 'Unutma Biçimleri': 779,\n",
       " 'Ayşecik Canımın İçi': 780,\n",
       " 'Baturalp': 781,\n",
       " 'Gelincik': 782,\n",
       " 'Abluka': 783,\n",
       " 'Başımız Belada': 784,\n",
       " 'Gelin': 785,\n",
       " 'Müsfer: Cin Kabilesi': 786,\n",
       " 'Güvercin Hırsızları': 787,\n",
       " 'Uzak': 788,\n",
       " 'Bina': 789,\n",
       " 'Geceden Önce': 790,\n",
       " 'Yok Artık': 791,\n",
       " 'Ankara Yazı': 792,\n",
       " 'Kuşatma Altında Aşk': 793,\n",
       " 'İnsanlar İkiye Ayrılır': 794,\n",
       " 'Cin Azabı': 795,\n",
       " 'Selam': 796,\n",
       " 'Siccin 6': 797,\n",
       " 'Beyaz Melek': 798,\n",
       " 'Fuad': 799,\n",
       " 'Nergis Hanım': 800,\n",
       " 'Firardayız': 801,\n",
       " \"Bir Zamanlar Anadolu'da\": 802,\n",
       " 'Can Tertip': 803,\n",
       " 'Sons Şans': 804,\n",
       " 'Kaplumbağalar da Uçar': 805,\n",
       " 'Cinni: Uyanış': 806,\n",
       " 'Hawar 2': 807,\n",
       " 'Şimdi Yandık': 808,\n",
       " 'Azem: Cin Karası': 809,\n",
       " 'Dirlik Düzenlik': 810,\n",
       " 'Bayi Toplantısı': 811,\n",
       " 'Okul': 812,\n",
       " 'Beş Vakit': 813,\n",
       " 'Azem 3: Cin Tohumu': 814,\n",
       " 'Sivas': 815,\n",
       " 'Kapıdaki Sır': 816,\n",
       " 'Bornova Bornova': 817,\n",
       " 'Masallardan Geriye Kalan': 818,\n",
       " 'Kashi': 819,\n",
       " 'Laz Kit': 820,\n",
       " 'Aşk Çağırırsan Gelir': 821,\n",
       " 'Hayde Bre': 822,\n",
       " 'Aaahh Belinda': 823,\n",
       " 'Sadece Farklı': 824,\n",
       " 'Düzensiz Düzenbazlar': 825,\n",
       " 'Gece 11:45': 826,\n",
       " 'İblisin Oğlu 13. Vahşet': 827,\n",
       " 'Kampüste Çıplak Ayaklar': 828,\n",
       " 'Bir Hikayem Var': 829,\n",
       " 'Randıman': 830,\n",
       " 'Tutturamayanlar': 831,\n",
       " 'Yozgat Blues': 832,\n",
       " 'Propaganda': 833,\n",
       " 'Bütün Saadetler Mümkündür': 834,\n",
       " 'Egy Nap': 835,\n",
       " 'Arapsaçı': 836,\n",
       " 'Zhit': 837,\n",
       " 'Lodos': 838,\n",
       " 'Zenne': 839,\n",
       " 'Ponente Feneri': 840,\n",
       " 'Vesaire Vesaire': 841,\n",
       " 'Morg': 842,\n",
       " 'Nuh Tepesi': 843,\n",
       " 'Gece': 844,\n",
       " 'Gassal': 845,\n",
       " 'Vay Babam Vay': 846,\n",
       " 'Keloğlan': 847,\n",
       " 'Ayna Ayna': 848,\n",
       " 'Ağır Abi': 849,\n",
       " 'Teslimiyet': 850,\n",
       " 'İnşaat 2': 851,\n",
       " 'Şeytan Papuçta': 852,\n",
       " 'Çalsın Sazlar': 853,\n",
       " 'Asansör': 854,\n",
       " 'Kutsal Bir Gün': 855,\n",
       " 'Bünyamin': 856,\n",
       " 'Yol Arkadaşım 2': 857,\n",
       " 'Geniş Aile Komşu Kızı': 858,\n",
       " 'The Lifeboat': 859,\n",
       " 'Musallat 2: Lanet': 860,\n",
       " 'Köpek': 861,\n",
       " 'Mazlum Kuzey': 862,\n",
       " 'Karantina XII': 863,\n",
       " 'İlk Temas': 864,\n",
       " 'Nene Hatun': 865,\n",
       " 'Kurtuluş Hattı': 866,\n",
       " 'Filme Gel': 867,\n",
       " 'Trileçe': 868,\n",
       " 'Deniz Seviyesi': 869,\n",
       " 'Sizi Seviyorum': 870,\n",
       " 'Linç: Arap Kadir': 871,\n",
       " 'Hasbihal': 872,\n",
       " 'Aşk Üzerine Söylenmemiş Her Şey': 873,\n",
       " 'Romantik Komedi': 874,\n",
       " 'Bircanlar Lokantası': 875,\n",
       " 'Stajyer Mafya': 876,\n",
       " 'İçimde Akan Nehir': 877,\n",
       " 'Nefes: Yer Eksi İki': 878,\n",
       " 'Delisin! Delisin!': 879,\n",
       " 'Yan Etki': 880,\n",
       " 'Güzelliğin Portresi': 881,\n",
       " 'Tasvie hesab': 882,\n",
       " 'Sükut Evi': 883,\n",
       " 'Garip Bülbül Neşet Ertaş': 884,\n",
       " 'Mandıra Filozofu İstanbul': 885,\n",
       " 'Melekler ve Kumarbazlar': 886,\n",
       " 'Münafık': 887,\n",
       " 'Cenazemize Hoş Geldiniz': 888,\n",
       " 'Nazar Değmez İnşallah': 889,\n",
       " 'Rüzgargülü': 890,\n",
       " 'Gözetleme Kulesi': 891,\n",
       " 'İstanbul': 892,\n",
       " 'Kalbim Yaralı': 893,\n",
       " 'Adı: Yunus': 894,\n",
       " 'Üç Harfliler 2: Hablis': 895,\n",
       " 'İki Gözüm Ahmet': 896,\n",
       " 'İllegal Hayatlar': 897,\n",
       " 'Kikoeteru, furi wo sita dake': 898,\n",
       " 'İçimdeki Balık': 899,\n",
       " 'Yaşamak Güzel Şey': 900,\n",
       " 'Paçi: Av Sanatı': 901,\n",
       " 'Ölümlü Dünya': 902,\n",
       " 'İyi Ki Doğdun Abla': 903,\n",
       " 'Un Padre No Tan Padre': 904,\n",
       " 'İnek Şaban': 905,\n",
       " 'Yakışıklı': 906,\n",
       " 'Omar ve Biz': 907,\n",
       " 'El Değmemiş Aşk': 908,\n",
       " 'Laz Vampir : Tirakula': 909,\n",
       " 'Aşkın Ömrü': 910,\n",
       " 'Gelenler': 911,\n",
       " 'Yeni Dünya': 912,\n",
       " 'Yol Kenarı': 913,\n",
       " 'Müthiş Bir Film': 914,\n",
       " 'Arada': 915,\n",
       " 'Körleşme': 916,\n",
       " 'Dönerse Senindir': 917,\n",
       " 'Annis Ölüm Gecesi': 918,\n",
       " 'Sebahat ve Melahat': 919,\n",
       " 'Türkler Geliyor : Adaletin Kılıcı': 920,\n",
       " 'The Bağcılar': 921,\n",
       " '11’e 10 Kala': 922,\n",
       " 'Üç Hayat': 923,\n",
       " 'Mezarlık': 924,\n",
       " 'Hayal Kurma Oyunları': 925,\n",
       " 'Aşk Kırmızı': 926,\n",
       " 'Semur': 927,\n",
       " 'Bulmaca Kulesi: Dev Kuşun Gizemi': 928,\n",
       " 'Kafalar Karışık': 929,\n",
       " 'İki İyi Çocuk': 930,\n",
       " '15/07 Şafak Vakti': 931,\n",
       " 'Son Takla': 932,\n",
       " 'Eski Sevgiliyi Unutmanın 10 Yolu': 933,\n",
       " '1 Erkek 1 Kadın 1 Düğün': 934,\n",
       " 'Yol Ayrımı: Hadi Baba Gene Yap': 935,\n",
       " '3 Dev Adam': 936,\n",
       " 'Mükemmel Aile': 937,\n",
       " \"Diktatör Adolf Hitler'in Hayatının Esrarengiz Yönleri\": 938,\n",
       " 'Hedef 2023': 939,\n",
       " 'Seni Seviyorum Adamım': 940,\n",
       " 'Sen Ben Lenin': 941,\n",
       " 'Kabus': 942,\n",
       " 'Kendime İyi Bak': 943,\n",
       " 'Adem’in Trenleri': 944,\n",
       " 'Allah Seviniz Dedi': 945,\n",
       " 'Turist Ömer Almanya’da': 946,\n",
       " 'Koltuk Belası': 947,\n",
       " 'Babamın Sesi': 948,\n",
       " 'Aykut Enişte': 949,\n",
       " 'Silemezler Gönlümden': 950,\n",
       " 'Hayat Öpücüğü': 951,\n",
       " \"Hayored Lema'ala\": 952,\n",
       " 'Fecr': 953,\n",
       " 'Ayşecik Çıtı Pıtı Kız': 954,\n",
       " 'Cellabi': 955,\n",
       " 'Batlır': 956,\n",
       " 'Araf 4: Meryem': 957,\n",
       " 'Ammar': 958,\n",
       " 'El Hass': 959,\n",
       " 'Şeytan-i İns': 960,\n",
       " 'Damat Koğuşu': 961,\n",
       " 'Erkekler': 962,\n",
       " 'Kötü Çocuk': 963,\n",
       " 'Reseba': 964,\n",
       " 'Can Dostlar': 965,\n",
       " 'Kaos: Örümcek Ağı': 966,\n",
       " 'Delibal': 967,\n",
       " 'Yudi: Yedikonuk Cinleri': 968,\n",
       " 'Ela ile Hilmi ve Ali': 969,\n",
       " 'Süt': 970,\n",
       " 'Loreak': 971,\n",
       " 'Eflâtun': 972,\n",
       " 'Çamaşırcı Güzeli': 973,\n",
       " 'Havar': 974,\n",
       " 'Aşk Geliyorum Demez': 975,\n",
       " 'Seni Seven Ölsün': 976,\n",
       " 'Katre': 977,\n",
       " 'Papatya ile Karabiber': 978,\n",
       " 'Yarım ile Yamalak': 979,\n",
       " 'At': 980,\n",
       " 'Biz Babasız Büyüdük': 981,\n",
       " 'Şeytan Geçidi Enhara': 982,\n",
       " 'Tafrigh': 983,\n",
       " 'Kahpe Bizans': 984,\n",
       " 'Aslan Marka Nihat': 985,\n",
       " 'Bir Damla Aşk': 986,\n",
       " 'Müfreze': 987,\n",
       " 'Kiraz Mevsimi': 988,\n",
       " 'Uçurum - Asla Arkana Bakma': 989,\n",
       " 'Tarzan Rıfkı': 990,\n",
       " 'Mahsusa': 991,\n",
       " 'Turist Ömer Boğa Güreşçisi': 992,\n",
       " 'Gölgelerin İçinde': 993,\n",
       " 'Makas': 994,\n",
       " 'Last Film Show': 995,\n",
       " 'Dadaş': 996,\n",
       " 'Kolay Para': 997,\n",
       " 'Ayakta Kal': 998,\n",
       " 'Sol Şerit': 999,\n",
       " 'Azap': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_movie = \"Recep İvedik 5\"\n",
    "valid_movies = list(embeds.keys())\n",
    "sim_movies_list = return_rank_list(embeds,guess_movie)\n",
    "sim_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_window():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Movie Guess Game\")\n",
    "    root.geometry(\"650x450\")\n",
    "    root.config(bg='#303030')\n",
    "\n",
    "    label = tk.Label(root, text=\"Guess the movie\", bg='#303030', fg='white', font=(\"Helvetica\", 16))\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    guess_entry = tk.Entry(root, bg='white', fg='#303030', font=(\"Helvetica\", 14))\n",
    "    guess_entry.pack(pady=10)\n",
    "\n",
    "    previous_guesses = []\n",
    "\n",
    "    def check_guess():\n",
    "        \n",
    "        user_input = guess_entry.get()\n",
    "        if (user_input == guess_movie):\n",
    "            result_label.config(text=\"You have won.\", bg='#303030', fg='white')\n",
    "            guess_entry.config(state=\"disabled\")\n",
    "            guess_button.config(state=\"disabled\")\n",
    "        if user_input not in valid_movies:\n",
    "            result_label.config(text=\"I do not know this movie\", bg='#303030', fg='white')\n",
    "        else:\n",
    "            previous_guesses.append((user_input, sim_movies_list[user_input]))\n",
    "            previous_guesses.sort(key=lambda x: x[1], reverse=False)\n",
    "            if (user_input == guess_movie):\n",
    "                result_label.config(text=\"You have won.\", bg='#303030', fg='white')\n",
    "                guess_entry.config(state=\"disabled\")\n",
    "                guess_button.config(state=\"disabled\")\n",
    "        previous_guesses_list.delete(0, tk.END)\n",
    "        for guess in previous_guesses:\n",
    "            previous_guesses_list.insert(tk.END, f\"{guess[0]}:{guess[1]}\")\n",
    "\n",
    "    guess_button = tk.Button(root, text=\"Guess\", command=check_guess, bg='#303030', fg='white', font=(\"Helvetica\", 14))\n",
    "    guess_button.pack(pady=10)\n",
    "\n",
    "    result_label = tk.Label(root, bg='#303030', fg='white')\n",
    "    result_label.pack(pady=20)\n",
    "\n",
    "    previous_guesses_label = tk.Label(root, text=\"Previous guesses:\", bg='#303030', fg='white', font=(\"Helvetica\", 14))\n",
    "    previous_guesses_label.pack(pady=10)\n",
    "\n",
    "    previous_guesses_list = tk.Listbox(root, bg='white', fg='#303030', font=(\"Helvetica\", 14))\n",
    "    previous_guesses_list.pack(pady=10)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "main_window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
